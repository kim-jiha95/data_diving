{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-2강 [실습] App 매출 순위 예측의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kim-jiha95/data_diving/blob/main/4_2%EA%B0%95_%5B%EC%8B%A4%EC%8A%B5%5D_App_%EB%A7%A4%EC%B6%9C_%EC%88%9C%EC%9C%84_%EC%98%88%EC%B8%A1%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALkngmAwVmBZ"
      },
      "source": [
        "# **🔥 Lesson 4 실습 🔥**\n",
        "\n",
        "🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠🐟🐡🐠\n",
        "\n",
        "## **Regression Practice - Apple App Sales Dataset(애플 앱 매출 순위 예측)**\n",
        "\n",
        "### **🎯 목적** \n",
        "\n",
        "앱 매출 순위를 예측하기 위해, 회귀(Regression) 분석을 하는 것이 이번 프로젝트의 목표입니다.\n",
        "\n",
        "### **🌈 특징**\n",
        "\n",
        "미국 Apple App Store Category별 매출 순위 예측을 위한 Top 500의 데이터\n",
        "\n",
        "우리는 여기서, 게임 카테고리의 앱 스토어 데이터를 사용합니다!\n",
        "\n",
        "### **📔 코드북**\n",
        "\n",
        "`app_sales_rank.csv`의 각 열별로 나타내는 정보는 다음과 같습니다.\n",
        "\n",
        "* `AppId`: 앱 등록번호\n",
        "* `Rank`: 앱 매출 순위\n",
        "* `Name`: 앱 이름\n",
        "* `Description`: 앱에 대한 설명 (텍스트)\n",
        "* `Category`: 카테고리 이름 ('Business', 'Games', .... '')\n",
        "* `Price`: 앱 구매 가격\n",
        "* `Seller`: 판매자\n",
        "* `ScreenShot`: 앱 설명에 포함된 스크린샷의 갯수\n",
        "* `Size`: 앱의 용량\n",
        "* `StarCurrentVersion`: 현재 버전에 대한 고객 별점의 평균\n",
        "* `RatingCurrentVersion`: 현재 버전에 대한 고객 별점의 총합 \n",
        "* `App_Age`: 현재 - 출시일 (일자)\n",
        "* 'Cluster': Description에 대한 k-means 클러스터링 결과로 1부터 3까지의 집단 번호  \n",
        "\n",
        "앱 매출 순위를 예측하는 회귀 모델을 찾는 것이 이번 장에서의 목표입니다. \n",
        "\n",
        "**1위부터 500위까지의 매출 순위를 담고 있는 `Rank`가 예측 목표(Target) 입니다**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHwppUGIXwnJ"
      },
      "source": [
        "## 📌 Step 0. 구글 드라이브 연동\n",
        "    \n",
        "Google Drive에 업로드한 데이터셋 파일 'app_sales.csv'와 해당 파일이 존재하는 자신만의 path (경로)를 입력\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqkxTD8xXPT7"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/') \n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/datascience') ## 현재 작업 환경으로 설정한 경로를 입력하세요"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z184kqa8YRkL"
      },
      "source": [
        "## 📌 Step 1. 필요한 패키지와 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIZUXHQHYE5D"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import warnings         # warnings : 버전 충돌 및 특정 예외 처리를 위해 불러온 내장 모듈\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zei58GiYo-b"
      },
      "source": [
        "# App 데이터셋 가져오기\n",
        "app_df = pd.read_csv('./app_sales.csv')\n",
        "app_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SK5drR7np7o"
      },
      "source": [
        "pd.read_csv(\"https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa1763c3d-02ce-49fe-92fa-f9c357c46f0c%2Fapp_sales.csv?table=block&id=17f04312-6894-40f0-a416-35ea1f66252a&name=app_sales.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P43khUbc8Frn"
      },
      "source": [
        "##📌 Step 2. 데이터셋 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpBc8mMOYuXV"
      },
      "source": [
        "# 데이터셋의 크기 확인하기\n",
        "app_df.???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vy_KoJAY2yV"
      },
      "source": [
        "# 데이터셋의 기초 정보 확인하기\n",
        "app_df.???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpJ6WbVaokdX"
      },
      "source": [
        "# categorical\n",
        "app_df.describe(include='O')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VSdqx82HUFi"
      },
      "source": [
        "# 데이터의 타입들 살펴보기\n",
        "app_df.???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7GThzYWsZWJ"
      },
      "source": [
        "# 데이터 시각화해보기\n",
        "???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u0IMOt9pGo1"
      },
      "source": [
        "sns.pairplot(app_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByaxSSFbRk2z"
      },
      "source": [
        "## **회귀 분석을 통해 통계량을 확인하고 개선점을 찾아보기**!\n",
        "\n",
        "- H0: 귀무 가설: 모든 설명 변수가 종속 변수(y)에 아무런 영향을 주지 못한다 \n",
        "\n",
        "- H1: 대립 가설: 적어도 하나의 설명 변수가 종속 변수(y)에 영향을 준다. \n",
        "\n",
        "- p.value < 0.05 (통계적 유의성)\n",
        "\n",
        "- AIC: 회귀 변수의 귀납적 선택을 위한 기준 통계량\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAIjMbGEp_cH"
      },
      "source": [
        "app_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b819pShGS71b"
      },
      "source": [
        "# 먼저 불필요한 인덱스 번호, 설명문(Description), 앱 고유 번호(AppId), 이름(Name), 그리고 판매자(Seller) 인덱스 제거하기\n",
        "app_df = ???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4n2QSdbVvPv"
      },
      "source": [
        "app_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmH1SoCTtmyn"
      },
      "source": [
        " **4-1강에서 배운 내용을 토대로**  \n",
        "X데이터와 Y데이터를 분리 > 상수항 추가 > 모델 추가 > 학습 > 결과 보기 순으로 한번에!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpBCA_pXRhaN"
      },
      "source": [
        "# 사실상 target을 나타내는 'Rank'를 제외한 변수 이름을 추출 \n",
        "feature_names = ???    # 실행결과는 변수 이름을 담고 있는 리스트 : ['ReleaseDate', 'Category', 'Screenshot', .... ] \n",
        "\n",
        "# 최종 종합 정보(Y)를 나타내는 'Rank'를 추출\n",
        "target_name = ???    # 실행결과는 'Rank'\n",
        "\n",
        "# 독립 변수(X) 열만 추출해내기\n",
        "# features = app_df.iloc[1:] \n",
        "features = ???\n",
        "\n",
        "# 종속 변수(Y) 열만 추출해내기\n",
        "target = ???\n",
        "\n",
        "# 정보가 담길 상수항 추가하기\n",
        "features_1 = ???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQGQZh_Zrbcs"
      },
      "source": [
        "features_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fRJTt9pr-8T"
      },
      "source": [
        "# 모델 제작 및 학습\n",
        "multi_model = ??? \n",
        "fitted_multi_model = ???\n",
        "\n",
        "#결과 보기\n",
        "fitted_multi_model.summary()\n",
        "\n",
        "# Category에 string이 있어 에러가 뜸 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLMWL5CtrUxP"
      },
      "source": [
        "# 모델 제작 및 학습\n",
        "#  Category  제외??\n",
        "multi_model = ???\n",
        "fitted_multi_model = multi_model.fit()\n",
        "\n",
        "#결과 보기\n",
        "fitted_multi_model.summary()\n",
        "\n",
        "##  NaN이 있어 에러가 뜸"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-7JG5e0dQrf"
      },
      "source": [
        "### 👆 네, 위의 결과처럼.... 활용하고 싶으나 그대로 쓰기 어려운 데이터가 존재할 수 있습니다.\n",
        "\n",
        "#### **Q) 수치형 자료가 아닌 경우에는 어떻게 해야 할까?** \n",
        "\n",
        "* 카테고리 : ['Buisness', 'Games', 'Education', 'Finance', 'Medical', 'Music', 'Productivity', 'Books']\n",
        "\n",
        "  👿 `ValueError: could not convert string to float: 'Business'`\n",
        "\n",
        "#### **Q) 결측 값 또는 이상치에 대해서는 어떻게 처리해야 할까?**\n",
        "\n",
        "* NaN 또는 NA values\n",
        "\n",
        "  👿 `MissingDataError: exog contains inf or nans`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK9lDMzcaKqu"
      },
      "source": [
        "##📌 Step 3. 데이터 전처리\n",
        "\n",
        "### **① Dummy 변수 도입하기**\n",
        "\n",
        "⏰ 시간을 0시부터 23시까지 나누어야 하는 것처럼, 데이터를 별도로 나누어야 하는 경우가 발생할 수 있습니다.\n",
        "\n",
        "- **범주형 데이터는 수치형 데이터**로 바꾸어 표현하고\n",
        "\n",
        "- **수치화된 범주형 데이터**를 하나의 열 마다 **가변수화** 하여 나타내면 \n",
        "\n",
        "기계 학습에 있어서 가장 바람직한 형태의 데이터에 가까워질 수 있습니다.\n",
        "\n",
        "##⚓ 예시 ⚓\n",
        "* `season`: 계절 (`1`:봄, `2`:여름, `3`:가을, `4`:겨울)\n",
        "* `mnth`: 달 (`1` ~ `12`)\n",
        "* `hr`: 시간 (`0` ~ `23`)\n",
        "* `weekday`: 요일 (`0` ~ `6`) \n",
        "* `weathersit`:\n",
        "    * `1`: 맑거나 조금 흐림\n",
        "    * `2`: 안개 및 흐림\n",
        "    * `3`: 가벼운 눈, 비, 뇌우\n",
        "    * `4`: 많은 비, 눈, 뇌우\n",
        "\n",
        "\n",
        "### 🧠 **기억하기!! 데이터 전처리를 위한 수치화(이산화) 작업**\n",
        "\n",
        "이전에 우리는 범주형과 수치형의 차이에 대해서 배웠습니다.\n",
        "\n",
        "그리고 컴퓨터는 범주형 자료를 알아먹을 수(?) 없다는 사실도 알고 있습니다.\n",
        "\n",
        "---\n",
        "\n",
        "😶 : 오늘 날씨가 맑니?\n",
        "\n",
        "🤖 : ?\n",
        "\n",
        "😡 : is the weather '1' ?\n",
        "\n",
        "🤖 : ! 11011010000101....\n",
        "\n",
        "🤯 : ... ㅡㅡ;;\n",
        "\n",
        "🤖 : ㅇㅇ '1'\n",
        "\n",
        "😑 : ...\n",
        "\n",
        "---\n",
        "\n",
        "컴퓨터와 저 멀리 행성에 사는 외계인의 공통점을 **굳이** 뽑는다면... 수학으로 대화를 해야 한다는 점이라 할 수 있겠죠.\n",
        "\n",
        "* 범주형: 순위, 명목\n",
        " \n",
        "  - 막대그래프, 도수 분포표, 원형 그래프로 표현\n",
        "\n",
        "* 수치형: 연속, 이산\n",
        " \n",
        "  - Box plot, 히스토그램으로 표현\n",
        "\n",
        "```python\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "make_dummy = pd.get_dummies(불러올 데이터셋['범주형 자료인 열'])\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCCR2bGyaVKh"
      },
      "source": [
        "💫 **for 문을 이용해서 일괄적으로 이산화하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVX2wqjTsc34"
      },
      "source": [
        "app_df.Category.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn5R7ZJMaY6x"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "# .copy()를 사용해서 백업 데이터 생성해두기\n",
        "app_df_dummy = app_df.copy()\n",
        "\n",
        "# 범주형 데이터 목록\n",
        "app_df.drop('Category', axis=1, inplace=True)\n",
        "category_list = ['Cluster']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvOu93IPtFSy"
      },
      "source": [
        "#for문 이용하기\n",
        "for category in category_list:\n",
        "    dummies = ???\n",
        "    app_df_dummy = ???\n",
        "\n",
        "# 이산형 데이터로 바꾼 이후의 모습 \n",
        "print(sorted(app_df_dummy.columns.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTGG6CImtllD"
      },
      "source": [
        "app_df_dummy.drop('Category', axis=1, inplace=True)\n",
        "app_df_dummy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vXvlThyupig"
      },
      "source": [
        "### **② 불필요한 변수 제거 및 변수 순서 변경**\n",
        "\n",
        "p-value, AIC만 가지고 특정 변수가 불필요하다고 항상 얘기할 수는 없지만, \n",
        "\n",
        "이전 4-1 강에서 언급했던 Step에 맞추어 통계치를 보면서 변수 삭제 및 추가를 진행할 수 있으며,\n",
        "\n",
        "위의 에러 메세지처럼 문제가 발생하는 경우에도 변수 속성 수정 및 최대 열 삭제까지 가능합니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZb6pOayY5ih"
      },
      "source": [
        "# 이미 위에서 불필요한 앱 고유 번호(AppId), 이름(Name), 그리고 버전(Version) 인덱스는 제거했습니다!\n",
        "##app_df = app_df.drop(['AppId', 'Name', 'Version'], axis = 1)\n",
        "\n",
        "# 헷갈리지 않도록 dummy set을 만들고 난 원형을 지우기.\n",
        "app_df_dummy = ???\n",
        "\n",
        "# 해당 데이터셋의 열 순서가 설명변수(X) -- 종속변수(Y)로 확실히 구분될 수 있도록 정리\n",
        "app_df_dummy = app_df_dummy[['App_Age', 'Cluster_1', 'Cluster_2', 'Cluster_3', 'Price', 'RatingCurrentVersion', 'Screenshot', 'Size', 'StarCurrentVersion', 'Rank']]\n",
        "\n",
        "# 확인\n",
        "app_df_dummy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVwSQ9r3wDjg"
      },
      "source": [
        "#### **이상치 제거해보기!**\n",
        "\n",
        "- **Z score**를 활용해보기\n",
        "\n",
        "  - Z = (x - mean) / std\n",
        "\n",
        "  - Z-score = 0, 평균과 동일\n",
        "\n",
        "  - Z-score = 1, 평균으로부터 1 표준편차가 높은 상태\n",
        "\n",
        "  - Z-score = +- 3의 경우 이상치로 간주 \n",
        "\n",
        "- **Quantile** 활용해보기\n",
        "\n",
        "  - IQR = Q3 - Q1\n",
        "\n",
        "  - 이상치의 범위: Q1 - 1.5IQR > Value or Q3 + 1.5IQR < Value \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JifMfcI0vyAt"
      },
      "source": [
        "app_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hGYXEtuv_9t"
      },
      "source": [
        "app_df_dummy.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISGZ7FMHvpoj"
      },
      "source": [
        "# Features의 이상치 제거\n",
        "Size_mean = ??? ; print(Size_mean)\n",
        "RCV_mean =  ??? ; print(RCV_mean)\n",
        "Age_mean =  ??? ; print(Age_mean)\n",
        "\n",
        "Size_std = ??? ; print(Size_std)\n",
        "RCV_std = ??? ; print(RCV_std)\n",
        "Age_std = ??? ; print(Age_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXVgozLjw4NU"
      },
      "source": [
        "for i, value in enumerate(['떡볶이', '치즈']):\n",
        "  print(i, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CFogMxqxXuX"
      },
      "source": [
        "app_df_dummy['Size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUJb6ANfwCAX"
      },
      "source": [
        "# Z - score = +-3를 초과 또는 미만의 값들을 NAN 처리하기\n",
        "for i, value in ???:\n",
        "    if ???\n",
        "        ???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U9TqncOxaYN"
      },
      "source": [
        "app_df_dummy['Size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yQ2mjpvx3An"
      },
      "source": [
        "# Z - score = +-3를 초과 또는 미만의 값들을 NAN 처리하기\n",
        "for i, value in ???:\n",
        "    if ???\n",
        "        ???\n",
        "\n",
        "# Z - score = +-3를 초과 또는 미만의 값들을 NAN 처리하기\n",
        "for i, value in ???:\n",
        "    if ???\n",
        "        ???\n",
        "\n",
        "# Z - score = +-3를 초과 또는 미만의 값들을 NAN 처리하기\n",
        "for i, value in ???:\n",
        "    if ???\n",
        "        ???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOho0TJOybQX"
      },
      "source": [
        "app_df_dummy.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaRt-cd8hQxR"
      },
      "source": [
        "#app_df_dummy = app_df_dummy.dropna(axis = 0)\n",
        "## Features의 이상치 제거\n",
        "#size_q1 = np.percentile(app_df_dummy['Size'], 25)\n",
        "#size_q3 = np.percentile(app_df_dummy['Size'], 75)\n",
        "#Size_iqr = size_q3 - size_q1\n",
        "\n",
        "#rav_q1 = np.percentile(app_df_dummy['RatingsAllVersions'], 25)\n",
        "#rav_q3 = np.percentile(app_df_dummy['RatingsAllVersions'], 75)\n",
        "#RAV_iqr = rav_q3 - rav_q1\n",
        "\n",
        "#price_q1 = np.percentile(app_df_dummy['Price'], 25)\n",
        "#price_q3 = np.percentile(app_df_dummy['Price'], 75) \n",
        "#Price_iqr = price_q3 - price_q1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL1j9gX4iNvH"
      },
      "source": [
        "# Q1 - 1.5IQR 미만, Q3 + 1.5IQR 초과의 값들을 NAN 처리하기\n",
        "#for i, value in enumerate(app_df_dummy['Size']):\n",
        "#    if value > size_q3 + 1.5 * Size_iqr or value < size_q1 - 1.5 * Size_iqr:\n",
        "#        app_df_dummy['Size'].iloc[i] = np.nan\n",
        "\n",
        "#for i, value in enumerate(app_df_dummy['RatingsAllVersions']):\n",
        "#    if value > rav_q3 + 1.5 * RAV_iqr or value < rav_q1 - 1.5 * RAV_iqr:\n",
        "#        app_df_dummy['RatingsAllVersions'].iloc[i] = np.nan\n",
        "\n",
        "#for i, value in enumerate(app_df_dummy['Price']):\n",
        "#    if value > price_q3 + 1.5 * Price_iqr or value < price_q1 - 1.5 * Price_iqr:\n",
        "#        app_df_dummy['Price'].iloc[i] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_m0p_W0lSFg"
      },
      "source": [
        "#app_df_dummy.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHmWT1N8hOLX"
      },
      "source": [
        "###**③ 결측치 제거하기** \n",
        "\n",
        "#####(1) 결측값이 하나라도 포함되는 경우 특정 행을 삭제해버리기\n",
        "\n",
        "**(1-2강 참고) NaN가 하나라도 포함된 행이면 삭제하는 코드**\n",
        "\n",
        "```\n",
        "df_items.dropna(axis = 0)\n",
        "```\n",
        "\n",
        "#####(2) 결측값이 과도하게 포함된 열을 삭제해버리기\n",
        "\n",
        "**(1-2강 참고) NaN가 하나라도 포함된 열이면 삭제하는 코드**\n",
        "\n",
        "```\n",
        "df_items.dropna(axis = 1)\n",
        "```\n",
        "\n",
        "#####(3) 결측값을 0으로 바꾸기\n",
        "\n",
        "**(1-2강 참고) 반드시 0일 필요는 없습니다. 평균 값이나 유사한 속성을 지니는 행의 값을 대신** 넣을 수 있습니다.\n",
        "\n",
        "```\n",
        "df_items.fillna(0)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTMGD0Pv1bhl"
      },
      "source": [
        "## 우선 결측치가 어디에 있는지 확인해볼까요?\n",
        "app_df_dummy.???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UtsKmzhz6sv"
      },
      "source": [
        "app_df_dummy.isnull().sum() # 갯수 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CJRQ-Nu2Bey"
      },
      "source": [
        "## 그렇다면 어떤 행에 있는지도 확인해보죠!\n",
        "for row_index in range(len(app_df_dummy)):\n",
        "    if app_df_dummy.isnull().sum(1)[row_index] > 0:\n",
        "        print(\"결측 값이 있는 {}번째 row\\n\".format(row_index), app_df_dummy.iloc[row_index])\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Zk6PkAye-x"
      },
      "source": [
        "# 특정 행만 누락되어 있는 경향이 있으므로 행만 삭제합니다.\n",
        "app_df_dummy_na = ???\n",
        "app_df_dummy_na"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZwlz3XYNiPL"
      },
      "source": [
        "#### **자 이제, 기초 통계량을 한 번 더 살펴볼까요?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTcCdTEmNc43"
      },
      "source": [
        "# 사실상 target을 나타내는 'Rank'를 제외한 변수 이름을 추출 \n",
        "feature_names = ???    # 실행결과는 변수 이름을 담고 있는 리스트 : ['ReleaseDate', 'Category', 'Screenshot', .... ] \n",
        "\n",
        "# 최종 종합 정보(Y)를 나타내는 'Rank'를 추출\n",
        "target_name = ???    # 실행결과는 'Rank'\n",
        "\n",
        "# 독립 변수(X) 열만 추출해내기\n",
        "features = ???\n",
        "\n",
        "# 종속 변수(Y) 열만 추출해내기\n",
        "target = ???\n",
        "\n",
        "# 정보가 담길 상수항 추가하기\n",
        "features_1 = ???\n",
        "\n",
        "# 모델 제작 및 학습\n",
        "multi_model = ???\n",
        "fitted_multi_model = ???\n",
        "\n",
        "#결과 보기\n",
        "fitted_multi_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOJmOu9bH20V"
      },
      "source": [
        "# p_value가 과도하게 높은 것 제거\n",
        "app_df_dummy_na = ???\n",
        "# size의 경우 (경험적으로) 이후 결과에 부정적 결과를 만들어서 먼저 삭제합니다.\n",
        "\n",
        "# 확인\n",
        "app_df_dummy_na"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWb4t_j-H0I"
      },
      "source": [
        "이제 **Case1(Dummy 변수 처리를 하지 않음)** 과 **Case2(Dummy 변수 처리를 함)**로 나누어서,\n",
        "\n",
        "\n",
        "1) 데이터셋을 분할하고 2) 모델을 학습시키고 3) 모델 성능을 평가해보도록 하겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AH7AXmLkiR-"
      },
      "source": [
        "# Dummy 변수가 없는 데이터셋 만들기\n",
        "# app_df_na = app_df_dummy_na.drop(['Category_Games', 'Cluster_1', 'Cluster_2', 'Cluster_3'], axis = 1)\n",
        "app_df_na = app_df_dummy_na.drop(['Cluster_1', 'Cluster_2', 'Cluster_3'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XvWMA7E8CWj"
      },
      "source": [
        "app_df_na"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYgIg6VZYxxY"
      },
      "source": [
        "# 훈련 데이터와 테스트 데이터로 분할하기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Case 1: Dummy 변수 처리를 하지 않은 데이터의 경우 \n",
        "# -> Dummy 처리가 된 Cluster라는 변수가 없는 자료\n",
        "y_target = app_df_na['Rank']\n",
        "X_features = app_df_na.drop(['Rank'], axis = 1, inplace = False)\n",
        "\n",
        "X_train, X_test, y_train, y_test = ???\n",
        "# Case 2: Dummy 변수 처리를 한 데이터의 경우 : '_d'로 이름을 붙여 구별\n",
        "# -> Dummy 처리가 된 Cluster라는 변수가 있는 자료\n",
        "y_target_d = app_df_dummy_na['Rank']\n",
        "X_features_d = app_df_dummy_na.drop(['Rank'], axis = 1, inplace = False)\n",
        "\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = ???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGzgTsjfYlYH"
      },
      "source": [
        "### **📌 Step 4. 모델 학습하기**\n",
        "\n",
        "⭐ Case1과 Case2를 나누었기 때문에, 모델 선언 역시  두 번으로 나누어서 진행합니다 ⭐\n",
        "\n",
        "- `lr` 과 `lr_d`\n",
        "\n",
        "다른 데이터로 학습을 시키기 때문에, 모델도 당연히 달라지겠지요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2tL9OQQQ6rQ"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 선형회귀모델 불러오기\n",
        "lr = ???\n",
        "lr_d = ???\n",
        "\n",
        "# 모델 학습하기\n",
        "lr.???\n",
        "lr_d.???\n",
        "\n",
        "# 모델의 예측 결과를 저장하기\n",
        "pred = ???\n",
        "pred_dummy = ???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0IzzTj1ZmfJ"
      },
      "source": [
        "### **📌 Step 5. 모델 평가하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J6cjv_KZly8"
      },
      "source": [
        "# 평가에 필요한 패키지 불러오기\n",
        "from sklearn.metrics import mean_squared_error , r2_score\n",
        "\n",
        "# MSE 방식으로 평가\n",
        "mse = ???\n",
        "mse_d = ???\n",
        "\n",
        "# RSME 방식으로 평가\n",
        "rmse = ???\n",
        "rmse_d = ???\n",
        "\n",
        "# print('Dummy를 적용하지 않은 경우')\n",
        "print('Cluster 변수 쓰지 않은 경우')\n",
        "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse , rmse))\n",
        "# R^2의 분산 지표를 통해, 모델의 예측 정확도 평가\n",
        "print('Variance score : {0:.3f}'.format(r2_score(y_test, pred)))\n",
        "print()\n",
        "\n",
        "# print('Dummy를 적용한 경우')\n",
        "print(\"Cluster 변수 사용한 경우\")\n",
        "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse_d, rmse_d))\n",
        "# R^2의 분산 지표를 통해, 모델의 예측 정확도 평가\n",
        "print('Variance score : {0:.3f}'.format(r2_score(y_test_d, pred_dummy)))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo9uesDc9QJE"
      },
      "source": [
        "MSE와 RMSE는 둘 다 오차를 의미하기 때문에 낮을수록 좋고,\n",
        "\n",
        "Variance score은 높을수록 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFANOxXSf73h"
      },
      "source": [
        "### **📌 Step 6. 데이터 변환을 통해 모델 개선하기** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LtYkZKw9QlG"
      },
      "source": [
        "data transformation은 data의 feature에 로그함수 등을 씌워 적당히 변환하는 것을 뜻합니다.  \n",
        "회귀모형을 위해 시행하는 data transformation을 통계학에서는 *Box-Cox technique*이라고도 합니다.\n",
        "\n",
        "data transformation은 보통 다음과 같은 경우에 실시합니다. \n",
        "\n",
        "* 변수의 범위를 실수 전체로 확장하기 위해 (로그변환, 시그모이드변환 등)\n",
        "* 변수의 정규성을 얻기 위해 (해석이 쉬워집니다)\n",
        "* (위의 경우를 일반화하여) 변수를 원하는 분포를 따르도록 만들 때\n",
        "* 분산안정변환 (상수의 분산을 갖게 하기 위해서)\n",
        "\n",
        "출처: https://en.wikipedia.org/wiki/Data_transformation_(statistics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxIN3bbJgbW4"
      },
      "source": [
        "# Features의 mean만 가볍게 살펴봅시다\n",
        "X_features_d.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud4pDhPCgy77"
      },
      "source": [
        "# Target의 mean만 가볍게 살펴봅시다\n",
        "y_target_d.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7flx6bhSoFZ"
      },
      "source": [
        "🙊 Target인 'Rank'가 의심스럽다... (순위라는 점에 집중해보세요!)\n",
        "\n",
        "🙊 Features인 Size, RatingsAllversions 또한 개선이 필요해 보인다... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iM4Pp9282bC"
      },
      "source": [
        "\n",
        "* Rank는 보통 범주형 자료, 특히 순서가 있는 범주형 자료(ordinal data)로 생각하는 경우가 많습니다.\n",
        "* 그러나 이 문제처럼 수가 매우 많은 경우 수치형 자료로 생각해 회귀모형을 적합할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDs9rRwCZvSq"
      },
      "source": [
        "# Target을 log로 변환\n",
        "y_target_log = -np.log1p(y_target_d.values.reshape(-1,1))    # shape을 제대로 정리해주고\n",
        "\n",
        "# (kwlee) log1p(x) = log(1+x)\n",
        "\n",
        "import seaborn as sns    # 시각화를 통해 전후 비교\n",
        "\n",
        "figure, axis = plt.subplots(1,2, figsize = (12,5))\n",
        "\n",
        "\"\"\"\n",
        "normalization는 정규화를 의미하며 자료를 정규분포를 따르게 만든다라는 의미로 보입니다.\n",
        "물론 이러한 의미로도 사용되기는 하지만\n",
        ">>> (https://campus.datacamp.com/courses/preprocessing-for-machine-learning-in-python/standardizing-data?ex=4)\n",
        "보통 normalization이라 하면 평균과 표준편차를 0과 1로 만들어주는 과정으로 주로 사용합니다.\n",
        "ex. Batch normalization, normalization in wikipedia\n",
        "\"\"\"\n",
        "\n",
        "sns.distplot(y_target_d, ax = axis[0], color = 'b')\n",
        "axis[0].set_title('Before Normalization')\n",
        "\n",
        "sns.distplot(y_target_log, ax = axis[1], color = 'r')\n",
        "axis[1].set_title('After Normalization')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXe2FQYY_Vde"
      },
      "source": [
        "sns.pairplot(X_features_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4lj2qxLT7aR"
      },
      "source": [
        "# Features도 log로 변환\n",
        "\n",
        "X_features_d['log_Age'] = np.log(X_features_d['App_Age'] + 1)\n",
        "X_features_d['log_RAV'] = np.log(X_features_d['RatingCurrentVersion'] + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6PnTLUpX_0S"
      },
      "source": [
        "X_features_d['log_Age']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS3UFgj4Xsnf"
      },
      "source": [
        "sns.pairplot(X_features_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK2a2eM1Yd7P"
      },
      "source": [
        "# 원본 데이터 삭제\n",
        "X_features_d = X_features_d.drop(['App_Age', 'RatingCurrentVersion'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHa6AUogTKXq"
      },
      "source": [
        "지금까지 **'원본 > dummy 생성 > 로그로 스케일링'**\n",
        "\n",
        "순서로 진행되었습니다. 마지막으로 스케일링 된 데이터셋을 학습시켜볼까요!\n",
        "\n",
        "과정은 똑같고 `train_test_split()`에 들어갈 데이터만 다릅니다.\n",
        "\n",
        "- Feature 데이터셋 : `X_features_d` - 더미 변수 처리가 된 feature 데이터\n",
        "- Target 데이터셋 : `y_target_log` - log가 된 target 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yacZVfIxaF_0"
      },
      "source": [
        "# 로그 변환된 y_target_log를 이용해서 다시 데이터를 분할 \n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_d, y_target_log, test_size=0.3, random_state=2)\n",
        "\n",
        "lr_log = LinearRegression()\n",
        "lr_log.fit(X_train, y_train)\n",
        "predict = lr_log.predict(X_test)\n",
        "\n",
        "# MSE 방식으로 평가\n",
        "mse = mean_squared_error(y_test, predict)\n",
        "# RSME 방식으로 평가\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse , rmse))\n",
        "# R^2의 분산 지표를 통해, 모델의 예측 정확도 평가\n",
        "print('Variance score : {0:.3f}'.format(r2_score(y_test, predict))) \n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1UrikqPAARk"
      },
      "source": [
        "# 로그 변환된 y_target_log를 이용해서 다시 데이터를 분할 \n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_d, y_target, test_size=0.3, random_state=2)\n",
        "\n",
        "lr_log = LinearRegression()\n",
        "lr_log.fit(X_train, y_train)\n",
        "predict = lr_log.predict(X_test)\n",
        "\n",
        "# MSE 방식으로 평가\n",
        "mse = mean_squared_error(y_test, predict)\n",
        "# RSME 방식으로 평가\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse , rmse))\n",
        "# R^2의 분산 지표를 통해, 모델의 예측 정확도 평가\n",
        "print('Variance score : {0:.3f}'.format(r2_score(y_test, predict))) \n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he3dx730AEjw"
      },
      "source": [
        "features = X_features_d\n",
        "\n",
        "target = y_target_log\n",
        "\n",
        "features_1 = sm.add_constant(features, has_constant = 'add')\n",
        "\n",
        "multi_model = sm.OLS(target, features_1.astype(float))\n",
        "fitted_multi_model = multi_model.fit()\n",
        "\n",
        "#결과 보기\n",
        "fitted_multi_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}